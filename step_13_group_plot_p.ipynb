{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots saved at /home/localadmin/hpc_mount/Cortical_Microstructure_Changes_in_Schizophrenia/new_group_results/combined\n",
    "\n",
    "Dots in box plot are the averaged values in significant clusters for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from mayavi import mlab\n",
    "from surfer import Brain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def setup_freesurfer():\n",
    "    \"\"\"Initialize FreeSurfer environment\"\"\"\n",
    "    freesurfer_home = '/home/localadmin/freesurfer'\n",
    "    subjects_dir = \"/home/localadmin/hpc_mount/Cortical_Microstructure_Changes_in_Schizophrenia\"\n",
    "    os.environ['FREESURFER_HOME'] = freesurfer_home\n",
    "    os.environ['SUBJECTS_DIR'] = subjects_dir\n",
    "    \n",
    "    setup_cmd = f\"bash -c 'source {freesurfer_home}/SetUpFreeSurfer.sh; env'\"\n",
    "    try:\n",
    "        process = subprocess.Popen(setup_cmd, stdout=subprocess.PIPE, shell=True)\n",
    "        output, _ = process.communicate()\n",
    "        for line in output.decode().split('\\n'):\n",
    "            if '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                os.environ[key] = value\n",
    "        print(\"FreeSurfer environment initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up FreeSurfer: {e}\")\n",
    "        raise\n",
    "\n",
    "def find_cluster_file(glmdir_path, for_visualization=True):\n",
    "    \"\"\"Find appropriate cluster file in GLM directory\"\"\"\n",
    "    \n",
    "    if os.path.exists(glmdir_path):\n",
    "        print(f\"\\nLooking in directory: {glmdir_path}\")\n",
    "        all_files = os.listdir(glmdir_path)\n",
    "        print(\"All files:\", all_files)\n",
    "        \n",
    "        if for_visualization:\n",
    "            files = [f for f in all_files \n",
    "                    if 'perm' in f and 'cluster' in f and f.endswith('.mgh')]\n",
    "  \n",
    "        selected_file = files[0] if files else None\n",
    "        print(f\"Selected file: {selected_file}\")\n",
    "        return selected_file\n",
    "    return None\n",
    "\n",
    "def check_significance(base_path, param, contrast):\n",
    "    \"\"\"Check if parameter shows significant clusters\"\"\"\n",
    "    is_significant = False\n",
    "    hemis = ['lh', 'rh']\n",
    "    \n",
    "    for hemi in hemis:\n",
    "        glmdir = os.path.join(base_path, 'new_group_results',\n",
    "                           f'group_{hemi}_{param}_fwhm6_demeaned_{contrast}.glmdir',\n",
    "                           f'group_contrast_{contrast}')\n",
    "        \n",
    "        if os.path.exists(glmdir):\n",
    "            cluster_file = find_cluster_file(glmdir, for_visualization=True)\n",
    "            if cluster_file:\n",
    "                file_path = os.path.join(glmdir, cluster_file)\n",
    "                data = nib.load(file_path).get_fdata().squeeze()\n",
    "                if np.max(data) > 1.3:\n",
    "                    is_significant = True\n",
    "                    print(f\"Found significant cluster in {hemi} {param} {contrast}\")\n",
    "                    break\n",
    "    \n",
    "    return is_significant\n",
    "\n",
    "def calculate_pvalue(group1, group2, alternative='two-sided'):\n",
    "    \"\"\"\n",
    "    Calculate p-value for the difference between two independent groups using t-test.\n",
    "    \n",
    "    Parameters:\n",
    "    group1 (array-like): First group of observations\n",
    "    group2 (array-like): Second group of observations\n",
    "    alternative (str): The alternative hypothesis, one of 'two-sided', 'less', 'greater'\n",
    "    \n",
    "    Returns:\n",
    "    float: p-value\n",
    "    \"\"\"\n",
    "    # Perform independent t-test\n",
    "    t_stat, p_value = stats.ttest_ind(group1, group2, alternative=alternative)\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "def create_boxplot(data_dict, fig, ax):\n",
    "    sns.set_style(rc={'axes.facecolor': 'black',\n",
    "                     'figure.facecolor': 'black',\n",
    "                     'xtick.color': 'white',\n",
    "                     'ytick.color': 'white',\n",
    "                     'axes.edgecolor': 'white',\n",
    "                     'axes.labelcolor': 'white',\n",
    "                     'text.color': 'white'})\n",
    "    \n",
    "    all_data = []\n",
    "    labels = []\n",
    "    # Store data for Cohen's d calculation\n",
    "    ep_data = np.array(data_dict['EP']) if 'EP' in data_dict else None\n",
    "    hc_data = np.array(data_dict['HC']) if 'HC' in data_dict else None\n",
    "    \n",
    "    for group in ['EP', 'HC']:\n",
    "        if group in data_dict and len(data_dict[group]) > 0:\n",
    "            values = np.array(data_dict[group])\n",
    "            all_data.extend(values.flatten())\n",
    "            labels.extend([group] * len(values.flatten()))\n",
    "    \n",
    "    plot_data = pd.DataFrame({\n",
    "        'Group': labels,\n",
    "        'Value': all_data\n",
    "    })\n",
    "    \n",
    "    palette = {'EP': '#E41A1C', 'HC': '#377EB8'}\n",
    "    bp = sns.boxplot(data=plot_data, x='Group', y='Value',\n",
    "                    palette=palette, ax=ax)\n",
    "    \n",
    "    sns.swarmplot(data=plot_data, x='Group', y='Value',\n",
    "                  color='white', alpha=0.65, ax=ax)\n",
    "    \n",
    "    # Calculate and display Cohen's d\n",
    "    if ep_data is not None and hc_data is not None:\n",
    "        cohens_d = calculate_cohens_d(ep_data.flatten(), hc_data.flatten())\n",
    "        pvalue = calculate_pvalue(ep_data.flatten(), hc_data.flatten())\n",
    "        \n",
    "        # p-value first (higher position)\n",
    "        plt.text(0.5, 0.90, f\"p = {pvalue:.2g}\", \n",
    "                transform=ax.transAxes, color='white',\n",
    "                horizontalalignment='center', fontsize=20)  # Increased font size\n",
    "        \n",
    "        # Cohen's d below it\n",
    "        plt.text(0.5, 0.80, f\"Cohen's d = {cohens_d:.2g}\", \n",
    "                transform=ax.transAxes, color='white',\n",
    "                horizontalalignment='center', fontsize=20)  # Increased font size\n",
    "    \n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('')\n",
    "    ax.set_facecolor('black')\n",
    "    plt.setp(ax.spines.values(), color='white')\n",
    "    \n",
    "    # Increase font size for tick labels\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    \n",
    "    # Increase font size for legend\n",
    "    plt.legend(fontsize=16)\n",
    "    \n",
    "    # Increase font size for y-label\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=20)\n",
    "    \n",
    "    return bp\n",
    "\n",
    "def load_freesurfer_lut(filename):\n",
    "    \"\"\"Load a FreeSurfer-style colormap from file\"\"\"\n",
    "    data = np.loadtxt(filename)\n",
    "    # Normalize RGB values to 0-1 range\n",
    "    rgb_data = data[:, :3]  # Take only RGB columns\n",
    "    return LinearSegmentedColormap.from_list('custom', rgb_data)\n",
    "\n",
    "def create_brain_views(subject_id, hemi, sig_file, temp_file_base, output_path):\n",
    "    \"\"\"Create lateral and medial views of brain surface showing -log10(p-values)\"\"\"\n",
    "    try:\n",
    "        # Load the cluster data (-log10(p-values))\n",
    "        cluster_data = nib.load(sig_file).get_fdata().squeeze()\n",
    "        thresh = 1.3  # Threshold for significance\n",
    "        \n",
    "        views = ['lateral', 'medial']\n",
    "        temp_files = []\n",
    "        colorbar_files = []\n",
    "        \n",
    "        for view in views:\n",
    "            temp_file = f\"{temp_file_base}_{view}.png\"\n",
    "            temp_files.append(temp_file)\n",
    "            \n",
    "            brain = Brain(subject_id, hemi, 'inflated',\n",
    "                         background=\"black\",\n",
    "                         cortex=\"low_contrast\",\n",
    "                         size=(800, 600))\n",
    "            \n",
    "            # Get the actual maximum value from the data\n",
    "            max_value = np.max(cluster_data)\n",
    "            print(f\"Maximum -log10(p-value): {max_value}\")  # For debugging\n",
    "            # Load custom colormap\n",
    "            custom_cmap = load_freesurfer_lut('/home/localadmin/hpc_mount/Cortical_Microstructure_Changes_in_Schizophrenia/results/nih_iso.cmap')\n",
    "            # Display the actual -log10(p-values)\n",
    "            brain.add_data(cluster_data,\n",
    "                         min=thresh,  # Minimum threshold for significance\n",
    "                         max=max_value,  # Use actual maximum value\n",
    "                         mid=(thresh + max_value)/2,\n",
    "                         thresh=thresh,\n",
    "                         colormap='YlOrRd',\n",
    "                         alpha=1.0,\n",
    "                         smoothing_steps=0,\n",
    "                         colorbar=True,\n",
    "                         remove_existing=True)\n",
    "            \n",
    "            brain.show_view(view, distance=350)\n",
    "            \n",
    "            # Save temporary file for combined plot\n",
    "            brain.save_image(temp_file)\n",
    "            \n",
    "            # Save individual brain view\n",
    "            final_brain_file = os.path.join(output_path, 'individual', \n",
    "                                          f'{os.path.basename(temp_file_base)}_{view}.png')\n",
    "            brain.save_image(final_brain_file)\n",
    "            \n",
    "            mlab.close(brain._figures[0])\n",
    "            \n",
    "            # Save the colorbar separately\n",
    "            colorbar_file = os.path.join(\"/home/localadmin/hpc_mount/Cortical_Microstructure_Changes_in_Schizophrenia/new_group_results/individual\", f\"{os.path.basename(temp_file_base)}_{view}_colorbar.png\")\n",
    "            colorbar_files.append(colorbar_file)\n",
    "            \n",
    "            # Create a standalone colorbar\n",
    "            fig, ax = plt.subplots(figsize=(4, 0.5))  # Adjust size as needed\n",
    "            norm = plt.Normalize(vmin=thresh, vmax=max_value)\n",
    "            sm = plt.cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "            sm.set_array([])\n",
    "            cbar = plt.colorbar(sm, cax=ax, orientation='horizontal')\n",
    "            cbar.set_label('-log10(p-value)', color='white')\n",
    "            cbar.ax.yaxis.set_tick_params(color='white')\n",
    "            cbar.ax.tick_params(labelcolor='white')\n",
    "            plt.savefig(colorbar_file, bbox_inches='tight', dpi=300, facecolor='black')\n",
    "            plt.close(fig)\n",
    "        \n",
    "        return temp_files, np.any(cluster_data > thresh)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating brain views: {e}\")\n",
    "        return [], False\n",
    "\n",
    "def process_parameter(base_path, param, contrast, output_path, groups_data, counter):\n",
    "    hemis = ['lh', 'rh']\n",
    "    temp_dir = os.path.join(output_path, 'temp')\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        brain_images = []\n",
    "        brain_data = {hemi: {} for hemi in hemis}\n",
    "        \n",
    "        # Collect brain data\n",
    "        for hemi in hemis:\n",
    "            glmdir = os.path.join(base_path, 'new_group_results',\n",
    "                               f'group_{hemi}_{param}_fwhm6_demeaned_{contrast}.glmdir',\n",
    "                               f'group_contrast_{contrast}')\n",
    "            \n",
    "            cluster_file_name = find_cluster_file(glmdir, for_visualization=True)\n",
    "            \n",
    "            if cluster_file_name:\n",
    "                brain_data[hemi] = {\n",
    "                    'cluster': os.path.join(glmdir, cluster_file_name),\n",
    "                    'param': os.path.join(base_path, 'new_group_analysis', f'group_{hemi}_{param}.mgh'),\n",
    "                    'thickness': os.path.join(base_path, 'new_group_analysis', f'group_{hemi}_thickness.mgh')  # Add thickness path\n",
    "                }\n",
    "        \n",
    "        view_order = [(0, 'lateral'), (0, 'medial'), (1, 'medial'), (1, 'lateral')]\n",
    "        significant_data = []\n",
    "        significant_thickness = []  # New list for thickness data\n",
    "        \n",
    "        # Process brain views\n",
    "        for hemi_idx, view in view_order:\n",
    "            hemi = hemis[hemi_idx]\n",
    "            if 'cluster' in brain_data[hemi]:\n",
    "                temp_file_base = os.path.join(temp_dir, f'{contrast}_{param}_{hemi}')\n",
    "                temp_files, is_sig = create_brain_views('fsaverage', hemi, \n",
    "                                                      brain_data[hemi]['cluster'], \n",
    "                                                      temp_file_base,\n",
    "                                                      output_path)\n",
    "                \n",
    "                if temp_files:\n",
    "                    img = plt.imread(temp_files[view == 'medial'])\n",
    "                    brain_images.append(img)\n",
    "                \n",
    "                if view == 'lateral' and is_sig:\n",
    "                    cluster_data = nib.load(brain_data[hemi]['cluster']).get_fdata()\n",
    "                    sig_vertices = cluster_data > 1.3\n",
    "                    param_data = nib.load(brain_data[hemi]['param']).get_fdata()\n",
    "                    thickness_data = nib.load(brain_data[hemi]['thickness']).get_fdata()  # Load thickness data\n",
    "                    significant_data.append((sig_vertices, param_data))\n",
    "                    significant_thickness.append((sig_vertices, thickness_data))  # Store significant thickness data\n",
    "        \n",
    "        # Process data for both parameter and thickness boxplots\n",
    "        data_by_group = {'EP': None, 'HC': None}\n",
    "        thickness_by_group = {'EP': None, 'HC': None}  # New dictionary for thickness\n",
    "        \n",
    "        if significant_data:\n",
    "            for group in data_by_group:\n",
    "                group_indices = groups_data['group'] == group\n",
    "                group_values = []\n",
    "                thickness_values = []  # New list for thickness values\n",
    "                \n",
    "                for (sig_vertices, param_data), (_, thickness_data) in zip(significant_data, significant_thickness):\n",
    "                    significant_values = param_data[sig_vertices]\n",
    "                    significant_thick = thickness_data[sig_vertices]  # Get thickness values\n",
    "                    group_data = np.mean(significant_values, axis=0)[group_indices]\n",
    "                    group_thick = np.mean(significant_thick, axis=0)[group_indices]  # Get group thickness\n",
    "                    group_values.append(group_data)\n",
    "                    thickness_values.append(group_thick)\n",
    "                \n",
    "                if group_values:\n",
    "                    data_by_group[group] = np.mean(group_values, axis=0)\n",
    "                    thickness_by_group[group] = np.mean(thickness_values, axis=0)\n",
    "        \n",
    "        # Create parameter boxplot\n",
    "        if any(v is not None for v in data_by_group.values()):\n",
    "            # Parameter boxplot\n",
    "            box_fig = plt.figure(figsize=(8, 6))\n",
    "            box_ax = box_fig.add_subplot(111)\n",
    "            create_boxplot(data_by_group, box_fig, box_ax)\n",
    "            plt.ylabel(param.upper())\n",
    "            plt.savefig(os.path.join(output_path, 'individual', f'{contrast}_{param}_boxplot.png'),\n",
    "                       facecolor='black', bbox_inches='tight', dpi=300, pad_inches=0.1)\n",
    "            plt.close(box_fig)\n",
    "            \n",
    "            box_fig = plt.figure(figsize=(8, 6))\n",
    "            box_ax = box_fig.add_subplot(111)\n",
    "            create_boxplot(data_by_group, box_fig, box_ax)\n",
    "            plt.ylabel(param.upper())\n",
    "            param_box_img = fig_to_array(box_fig)\n",
    "            plt.close(box_fig)\n",
    "            brain_images.append(param_box_img)\n",
    "            \n",
    "            # Thickness boxplot\n",
    "            box_fig = plt.figure(figsize=(8, 6))\n",
    "            box_ax = box_fig.add_subplot(111)\n",
    "            create_boxplot(thickness_by_group, box_fig, box_ax)\n",
    "            plt.ylabel('Thickness (mm)')\n",
    "            plt.savefig(os.path.join(output_path, 'individual', f'{contrast}_{param}_thickness_boxplot.png'),\n",
    "                       facecolor='black', bbox_inches='tight', dpi=300, pad_inches=0.1)\n",
    "            plt.close(box_fig)\n",
    "            \n",
    "            box_fig = plt.figure(figsize=(8, 6))\n",
    "            box_ax = box_fig.add_subplot(111)\n",
    "            create_boxplot(thickness_by_group, box_fig, box_ax)\n",
    "            plt.ylabel('Thickness (mm)')\n",
    "            thickness_box_img = fig_to_array(box_fig)\n",
    "            plt.close(box_fig)\n",
    "            brain_images.append(thickness_box_img)\n",
    "        \n",
    "        # Create combined figure with 6 subplots (4 brain views + 2 boxplots)\n",
    "        fig, axes = plt.subplots(1, 6, figsize=(38, 8))  # Increased figure width\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        \n",
    "        letters = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "        \n",
    "        for idx, (ax, img) in enumerate(zip(axes, brain_images)):\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            if idx == 3:\n",
    "                ax.text(0.8, 0.9, 'R', color='white', fontsize=18,\n",
    "                        transform=ax.transAxes)\n",
    "            elif idx == 0:\n",
    "                text = ax.text(0.1, 0.92, f'{letters[counter]}) {param.upper()}: EP>HC', \n",
    "                            color='black', fontsize=18,\n",
    "                            transform=ax.transAxes,\n",
    "                            bbox=dict(facecolor='white', \n",
    "                                    alpha=1.0,\n",
    "                                    edgecolor='none',\n",
    "                                    pad=3))\n",
    "        \n",
    "        plt.savefig(os.path.join(output_path, 'combined', f'{contrast}_{param}_combined.png'),\n",
    "                    facecolor='black', bbox_inches='tight', dpi=300, pad_inches=0.1)\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {param} - {contrast}: {e}\")\n",
    "    finally:\n",
    "        if os.path.exists(temp_dir):\n",
    "            for file in os.listdir(temp_dir):\n",
    "                try:\n",
    "                    os.remove(os.path.join(temp_dir, file))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing temp file {file}: {e}\")\n",
    "            try:\n",
    "                os.rmdir(temp_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing temp directory: {e}\")\n",
    "\n",
    "# Helper function to convert figure to array\n",
    "def fig_to_array(fig):\n",
    "    fig.canvas.draw()\n",
    "    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    return data\n",
    "    \n",
    "def calculate_cohens_d(group1, group2):\n",
    "    \"\"\"Calculate Cohen's d effect size between two groups.\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_se = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_se\n",
    "    return cohens_d\n",
    "\n",
    "def main():\n",
    "    # Setup paths\n",
    "    base_path = '/home/localadmin/hpc_mount/Cortical_Microstructure_Changes_in_Schizophrenia'\n",
    "    output_path = os.path.join(base_path, 'new_group_results')\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_path, 'combined'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_path, 'individual'), exist_ok=True)\n",
    "    \n",
    "    # Setup FreeSurfer\n",
    "    setup_freesurfer()\n",
    "    \n",
    "    # Load group data\n",
    "    groups_data = pd.read_csv(os.path.join(base_path, \n",
    "                             'MRS_data_curated_+paths+avg_skeleton+registration.csv'))\n",
    "    \n",
    "    # Parameters and contrasts\n",
    "    parameters = ['md']\n",
    "    contrasts = ['EPHC']\n",
    "    \n",
    "    # Process each contrast\n",
    "    for contrast in contrasts:\n",
    "        print(f\"\\nProcessing {contrast} contrast...\")\n",
    "        significant_params = []\n",
    "        \n",
    "        # Find significant parameters\n",
    "        for param in parameters:\n",
    "            if check_significance(base_path, param, contrast):\n",
    "                significant_params.append(param)\n",
    "                print(f\"Found significant clusters for {param}\")\n",
    "        \n",
    "        # Create visualizations for significant parameters\n",
    "        counter = 0\n",
    "        for param in significant_params:\n",
    "            print(f\"Creating visualizations for {param}\")\n",
    "            process_parameter(base_path, param, contrast, output_path, groups_data, counter)\n",
    "            counter += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
